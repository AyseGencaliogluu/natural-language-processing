Step	Training Loss	Validation Loss	
100	        1.039700	    1.091044	100
200	        1.080800	    1.072065	200
300	        0.951100	    1.064427	300
400	        0.972600	    1.062067	400
500	        0.943800	    1.057607	500
Step: 20 | {'loss': 1.2273, 'grad_norm': 0.39788517355918884, 'learning_rate': 0.00019926062846580407, 'epoch': 0.07191011235955057}
Step: 40 | {'loss': 1.086, 'grad_norm': 0.30846983194351196, 'learning_rate': 0.00019186691312384475, 'epoch': 0.14382022471910114}
Step: 60 | {'loss': 1.0561, 'grad_norm': 0.47944504022598267, 'learning_rate': 0.0001844731977818854, 'epoch': 0.2157303370786517}
Step: 80 | {'loss': 1.0727, 'grad_norm': 0.3973972499370575, 'learning_rate': 0.00017707948243992608, 'epoch': 0.2876404494382023}
Step: 100 | {'loss': 1.0397, 'grad_norm': 0.4668258726596832, 'learning_rate': 0.00016968576709796673, 'epoch': 0.3595505617977528}
Step: 100 | {'eval_loss': 1.0910439491271973, 'eval_runtime': 12.4143, 'eval_samples_per_second': 4.028, 'eval_steps_per_second': 4.028, 'epoch': 0.3595505617977528}
Step: 120 | {'loss': 1.1052, 'grad_norm': 0.3427284061908722, 'learning_rate': 0.00016229205175600738, 'epoch': 0.4314606741573034}
Step: 140 | {'loss': 1.0728, 'grad_norm': 0.34924080967903137, 'learning_rate': 0.00015489833641404806, 'epoch': 0.503370786516854}
Step: 160 | {'loss': 1.0617, 'grad_norm': 0.3272159993648529, 'learning_rate': 0.00014750462107208874, 'epoch': 0.5752808988764045}
Step: 180 | {'loss': 1.0698, 'grad_norm': 0.42432454228401184, 'learning_rate': 0.0001401109057301294, 'epoch': 0.647191011235955}
Step: 200 | {'loss': 1.0808, 'grad_norm': 0.4251549243927002, 'learning_rate': 0.00013271719038817004, 'epoch': 0.7191011235955056}
Step: 200 | {'eval_loss': 1.0720645189285278, 'eval_runtime': 12.534, 'eval_samples_per_second': 3.989, 'eval_steps_per_second': 3.989, 'epoch': 0.7191011235955056}
Step: 220 | {'loss': 1.0291, 'grad_norm': 0.3034083843231201, 'learning_rate': 0.00012532347504621075, 'epoch': 0.7910112359550562}
Step: 240 | {'loss': 1.0836, 'grad_norm': 0.35633373260498047, 'learning_rate': 0.0001179297597042514, 'epoch': 0.8629213483146068}
Step: 260 | {'loss': 1.0116, 'grad_norm': 0.45638635754585266, 'learning_rate': 0.00011053604436229205, 'epoch': 0.9348314606741573}
Step: 280 | {'loss': 1.0812, 'grad_norm': 0.31490519642829895, 'learning_rate': 0.00010314232902033272, 'epoch': 1.0035955056179775}
Step: 300 | {'loss': 0.9511, 'grad_norm': 0.3213447034358978, 'learning_rate': 9.574861367837338e-05, 'epoch': 1.075505617977528}
Step: 300 | {'eval_loss': 1.0644267797470093, 'eval_runtime': 12.4247, 'eval_samples_per_second': 4.024, 'eval_steps_per_second': 4.024, 'epoch': 1.075505617977528}
Step: 320 | {'loss': 0.953, 'grad_norm': 0.42146435379981995, 'learning_rate': 8.835489833641405e-05, 'epoch': 1.1474157303370787}
Step: 340 | {'loss': 0.9259, 'grad_norm': 0.3696249723434448, 'learning_rate': 8.096118299445473e-05, 'epoch': 1.2193258426966291}
Step: 360 | {'loss': 0.9607, 'grad_norm': 0.33739739656448364, 'learning_rate': 7.356746765249538e-05, 'epoch': 1.2912359550561798}
Step: 380 | {'loss': 0.983, 'grad_norm': 0.3680097758769989, 'learning_rate': 6.617375231053606e-05, 'epoch': 1.3631460674157303}
Step: 400 | {'loss': 0.9726, 'grad_norm': 0.3873177468776703, 'learning_rate': 5.8780036968576715e-05, 'epoch': 1.4350561797752808}
Step: 400 | {'eval_loss': 1.062066674232483, 'eval_runtime': 12.4733, 'eval_samples_per_second': 4.009, 'eval_steps_per_second': 4.009, 'epoch': 1.4350561797752808}
Step: 420 | {'loss': 0.9718, 'grad_norm': 0.34500518441200256, 'learning_rate': 5.1386321626617373e-05, 'epoch': 1.5069662921348315}
Step: 440 | {'loss': 0.9297, 'grad_norm': 0.35962262749671936, 'learning_rate': 4.3992606284658045e-05, 'epoch': 1.5788764044943822}
Step: 460 | {'loss': 0.9361, 'grad_norm': 0.3853634297847748, 'learning_rate': 3.659889094269871e-05, 'epoch': 1.6507865168539326}
Step: 480 | {'loss': 0.8911, 'grad_norm': 0.4064565598964691, 'learning_rate': 2.920517560073937e-05, 'epoch': 1.722696629213483}
Step: 500 | {'loss': 0.9438, 'grad_norm': 0.3934769928455353, 'learning_rate': 2.1811460258780038e-05, 'epoch': 1.7946067415730336}
Step: 500 | {'eval_loss': 1.0576072931289673, 'eval_runtime': 12.5023, 'eval_samples_per_second': 3.999, 'eval_steps_per_second': 3.999, 'epoch': 1.7946067415730336}
Step: 520 | {'loss': 0.9457, 'grad_norm': 0.3608458340167999, 'learning_rate': 1.4417744916820703e-05, 'epoch': 1.8665168539325843}
Step: 540 | {'loss': 0.9673, 'grad_norm': 0.38950592279434204, 'learning_rate': 7.024029574861368e-06, 'epoch': 1.938426966292135}
Step: 558 | {'train_runtime': 3936.6709, 'train_samples_per_second': 2.261, 'train_steps_per_second': 0.142, 'total_flos': 3.409297817151283e+16, 'train_loss': 1.0132201512654622, 'epoch': 2.0}
TrainOutput(global_step=558, training_loss=1.0132201512654622, metrics={'train_runtime': 3936.6709, 'train_samples_per_second': 2.261, 'train_steps_per_second': 0.142, 'total_flos': 3.409297817151283e+16, 'train_loss': 1.0132201512654622, 'epoch': 2.0, 'step': 558})