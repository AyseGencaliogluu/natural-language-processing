
Step	Training Loss	Validation Loss	
100	        0.962900	    0.892408	100
200	        0.760700	    0.671656	200
300	        0.455900	    0.476851	300
400	        0.294500	    0.318757	400
500	        0.219300	    0.231275	500
Step: 20 | {'loss': 1.2187, 'grad_norm': 0.37411585450172424, 'learning_rate': 0.00019926062846580407, 'epoch': 0.07191011235955057}
Step: 40 | {'loss': 1.1029, 'grad_norm': 0.31589412689208984, 'learning_rate': 0.00019186691312384475, 'epoch': 0.14382022471910114}
Step: 60 | {'loss': 1.0433, 'grad_norm': 0.4003276824951172, 'learning_rate': 0.0001844731977818854, 'epoch': 0.2157303370786517}
Step: 80 | {'loss': 0.9393, 'grad_norm': 0.4468878507614136, 'learning_rate': 0.00017707948243992608, 'epoch': 0.2876404494382023}
Step: 100 | {'loss': 0.9629, 'grad_norm': 0.7525123953819275, 'learning_rate': 0.00016968576709796673, 'epoch': 0.3595505617977528}
Step: 100 | {'eval_loss': 0.8924084305763245, 'eval_runtime': 12.3929, 'eval_samples_per_second': 4.035, 'eval_steps_per_second': 4.035, 'epoch': 0.3595505617977528}
Step: 120 | {'loss': 0.858, 'grad_norm': 0.42114150524139404, 'learning_rate': 0.00016229205175600738, 'epoch': 0.4314606741573034}
Step: 140 | {'loss': 0.8901, 'grad_norm': 0.49180182814598083, 'learning_rate': 0.00015489833641404806, 'epoch': 0.503370786516854}
Step: 160 | {'loss': 0.8735, 'grad_norm': 0.5778251886367798, 'learning_rate': 0.00014750462107208874, 'epoch': 0.5752808988764045}
Step: 180 | {'loss': 0.768, 'grad_norm': 0.506064772605896, 'learning_rate': 0.0001401109057301294, 'epoch': 0.647191011235955}
Step: 200 | {'loss': 0.7607, 'grad_norm': 0.6865824460983276, 'learning_rate': 0.00013271719038817004, 'epoch': 0.7191011235955056}
Step: 200 | {'eval_loss': 0.6716558337211609, 'eval_runtime': 12.5014, 'eval_samples_per_second': 4.0, 'eval_steps_per_second': 4.0, 'epoch': 0.7191011235955056}
Step: 220 | {'loss': 0.7017, 'grad_norm': 0.6591493487358093, 'learning_rate': 0.00012532347504621075, 'epoch': 0.7910112359550562}
Step: 240 | {'loss': 0.6947, 'grad_norm': 0.7157627940177917, 'learning_rate': 0.0001179297597042514, 'epoch': 0.8629213483146068}
Step: 260 | {'loss': 0.6424, 'grad_norm': 0.7574021220207214, 'learning_rate': 0.00011053604436229205, 'epoch': 0.9348314606741573}
Step: 280 | {'loss': 0.5901, 'grad_norm': 0.819859504699707, 'learning_rate': 0.00010314232902033272, 'epoch': 1.0035955056179775}
Step: 300 | {'loss': 0.4559, 'grad_norm': 0.9836812019348145, 'learning_rate': 9.574861367837338e-05, 'epoch': 1.075505617977528}
Step: 300 | {'eval_loss': 0.47685110569000244, 'eval_runtime': 12.3956, 'eval_samples_per_second': 4.034, 'eval_steps_per_second': 4.034, 'epoch': 1.075505617977528}
Step: 320 | {'loss': 0.4127, 'grad_norm': 0.857617974281311, 'learning_rate': 8.835489833641405e-05, 'epoch': 1.1474157303370787}
Step: 340 | {'loss': 0.4092, 'grad_norm': 0.7774960398674011, 'learning_rate': 8.096118299445473e-05, 'epoch': 1.2193258426966291}
Step: 360 | {'loss': 0.3864, 'grad_norm': 0.968798041343689, 'learning_rate': 7.356746765249538e-05, 'epoch': 1.2912359550561798}
Step: 380 | {'loss': 0.3251, 'grad_norm': 0.9411283135414124, 'learning_rate': 6.617375231053606e-05, 'epoch': 1.3631460674157303}
Step: 400 | {'loss': 0.2945, 'grad_norm': 1.0206042528152466, 'learning_rate': 5.8780036968576715e-05, 'epoch': 1.4350561797752808}
Step: 400 | {'eval_loss': 0.31875747442245483, 'eval_runtime': 12.6252, 'eval_samples_per_second': 3.96, 'eval_steps_per_second': 3.96, 'epoch': 1.4350561797752808}
Step: 420 | {'loss': 0.2634, 'grad_norm': 0.7877753973007202, 'learning_rate': 5.1386321626617373e-05, 'epoch': 1.5069662921348315}
Step: 440 | {'loss': 0.2737, 'grad_norm': 1.1358318328857422, 'learning_rate': 4.3992606284658045e-05, 'epoch': 1.5788764044943822}
Step: 460 | {'loss': 0.2541, 'grad_norm': 0.829729437828064, 'learning_rate': 3.659889094269871e-05, 'epoch': 1.6507865168539326}
Step: 480 | {'loss': 0.2242, 'grad_norm': 0.952217161655426, 'learning_rate': 2.920517560073937e-05, 'epoch': 1.722696629213483}
Step: 500 | {'loss': 0.2193, 'grad_norm': 0.8945401906967163, 'learning_rate': 2.1811460258780038e-05, 'epoch': 1.7946067415730336}
Step: 500 | {'eval_loss': 0.23127469420433044, 'eval_runtime': 12.4765, 'eval_samples_per_second': 4.008, 'eval_steps_per_second': 4.008, 'epoch': 1.7946067415730336}
Step: 520 | {'loss': 0.2007, 'grad_norm': 0.9252761006355286, 'learning_rate': 1.4417744916820703e-05, 'epoch': 1.8665168539325843}
Step: 540 | {'loss': 0.2155, 'grad_norm': 0.8749971985816956, 'learning_rate': 7.024029574861368e-06, 'epoch': 1.938426966292135}
Step: 558 | {'train_runtime': 3942.7388, 'train_samples_per_second': 2.257, 'train_steps_per_second': 0.142, 'total_flos': 3.3843016447156224e+16, 'train_loss': 0.5793058748313603, 'epoch': 2.0}
TrainOutput(global_step=558, training_loss=0.5793058748313603, metrics={'train_runtime': 3942.7388, 'train_samples_per_second': 2.257, 'train_steps_per_second': 0.142, 'total_flos': 3.3843016447156224e+16, 'train_loss': 0.5793058748313603, 'epoch': 2.0, 'step': 558})